{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dd66b6a",
   "metadata": {},
   "source": [
    "# Coffee CNN Fine-tuning Runner\n",
    "\n",
    "This notebook executes the coffee level detection CNN fine-tuning script using command line execution and logs all output to `finetune_log.txt` for monitoring and analysis.\n",
    "\n",
    "## Features\n",
    "- Real-time command execution with output capture\n",
    "- Comprehensive logging to text file with timestamps\n",
    "- Progress monitoring during training\n",
    "- Results parsing and display\n",
    "- Configurable training parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f5f0ce",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import subprocess, os, datetime, and other necessary libraries for command execution and file handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03727b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import threading\n",
    "import queue\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2923f30a",
   "metadata": {},
   "source": [
    "## 2. Setup Logging Configuration\n",
    "\n",
    "Configure logging to write all output to `finetune_log.txt` with timestamps and proper formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bfc725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging configuration\n",
    "LOG_FILE = \"finetune_log.txt\"\n",
    "SCRIPT_PATH = \"coffee_level_detection/training/finetune_coffeeCNN.py\"\n",
    "\n",
    "def setup_logging():\n",
    "    \"\"\"Initialize the log file with session header.\"\"\"\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    header = f\"\"\"\n",
    "{'='*80}\n",
    "Coffee CNN Fine-tuning Session Started\n",
    "Timestamp: {timestamp}\n",
    "Log File: {LOG_FILE}\n",
    "Script: {SCRIPT_PATH}\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "    with open(LOG_FILE, 'w', encoding='utf-8') as f:\n",
    "        f.write(header)\n",
    "    print(f\"‚úÖ Logging initialized: {LOG_FILE}\")\n",
    "\n",
    "def log_message(message, print_also=True):\n",
    "    \"\"\"Log a message to the file with timestamp.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    log_entry = f\"[{timestamp}] {message}\\n\"\n",
    "    \n",
    "    with open(LOG_FILE, 'a', encoding='utf-8') as f:\n",
    "        f.write(log_entry)\n",
    "    \n",
    "    if print_also:\n",
    "        print(f\"[{timestamp}] {message}\")\n",
    "\n",
    "# Initialize logging\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3b92ca",
   "metadata": {},
   "source": [
    "## 3. Define Command Execution Function\n",
    "\n",
    "Create a function to execute the fine-tuning script with real-time output capture and logging to the text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e9d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_finetune_command(command_args, real_time_output=True):\n",
    "    \"\"\"\n",
    "    Execute the fine-tuning command with real-time output capture and logging.\n",
    "    \n",
    "    Args:\n",
    "        command_args: List of command arguments\n",
    "        real_time_output: Whether to show real-time output in notebook\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (return_code, stdout, stderr)\n",
    "    \"\"\"\n",
    "    log_message(f\"üöÄ Executing command: {' '.join(command_args)}\")\n",
    "    \n",
    "    try:\n",
    "        # Start the process\n",
    "        process = subprocess.Popen(\n",
    "            command_args,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,  # Merge stderr with stdout\n",
    "            text=True,\n",
    "            bufsize=1,\n",
    "            universal_newlines=True\n",
    "        )\n",
    "        \n",
    "        output_lines = []\n",
    "        \n",
    "        # Read output line by line in real-time\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == '' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                line = output.strip()\n",
    "                output_lines.append(line)\n",
    "                \n",
    "                # Log to file\n",
    "                log_message(line, print_also=False)\n",
    "                \n",
    "                # Show in notebook if requested\n",
    "                if real_time_output:\n",
    "                    print(line)\n",
    "        \n",
    "        # Wait for process to complete\n",
    "        return_code = process.poll()\n",
    "        \n",
    "        # Final status\n",
    "        if return_code == 0:\n",
    "            log_message(\"‚úÖ Command completed successfully\")\n",
    "        else:\n",
    "            log_message(f\"‚ùå Command failed with return code: {return_code}\")\n",
    "        \n",
    "        return return_code, '\\n'.join(output_lines), ''\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå Error executing command: {str(e)}\"\n",
    "        log_message(error_msg)\n",
    "        return 1, '', str(e)\n",
    "\n",
    "def read_log_tail(num_lines=20):\n",
    "    \"\"\"Read the last N lines from the log file.\"\"\"\n",
    "    try:\n",
    "        with open(LOG_FILE, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            return ''.join(lines[-num_lines:])\n",
    "    except FileNotFoundError:\n",
    "        return \"Log file not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error reading log: {e}\"\n",
    "\n",
    "print(\"‚úÖ Command execution functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565bade0",
   "metadata": {},
   "source": [
    "## 4. Configure Fine-tuning Parameters\n",
    "\n",
    "Set up command line arguments for the fine-tuning script including learning rate, epochs, batch size, and file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d25c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning configuration parameters\n",
    "config = {\n",
    "    # Model paths\n",
    "    'pretrained': 'coffeeCNN_finetuned_20251002_195526.pth',  # Use latest pretrained model\n",
    "    'output': f'coffeeCNN_finetuned_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.pth',\n",
    "    \n",
    "    # Data paths\n",
    "    'manual_levels': 'manual_levels',\n",
    "    'img_dir': 'processed_images',\n",
    "    \n",
    "    # Training parameters\n",
    "    'lr': 1e-6,              # Very conservative learning rate\n",
    "    'epochs': 10,            # Max epochs (early stopping will likely trigger first)\n",
    "    'batch_size': 8,         # Small batch size for stable training\n",
    "    'num_classes': 11,       # Coffee levels 0-10\n",
    "    'early_stopping': 3,     # Early stopping patience\n",
    "    'dropout': 0.3,          # Dropout rate for regularization\n",
    "    \n",
    "    # Data filtering\n",
    "    'max_per_class': 100,    # Maximum samples per class\n",
    "    'min_per_class': 5,      # Minimum samples per class\n",
    "    \n",
    "    # Options\n",
    "    'freeze_layers': True,   # Freeze early layers (set to False to add --no-freeze)\n",
    "    'dry_run': False         # Set to True to only show data statistics\n",
    "}\n",
    "\n",
    "def build_command(config):\n",
    "    \"\"\"Build the command line arguments from configuration.\"\"\"\n",
    "    cmd = ['python', '-m', SCRIPT_PATH.replace('/', '.').replace('.py', '')]\n",
    "    \n",
    "    # Add arguments\n",
    "    cmd.extend(['--pretrained', config['pretrained']])\n",
    "    cmd.extend(['--output', config['output']])\n",
    "    cmd.extend(['--manual-levels', config['manual_levels']])\n",
    "    cmd.extend(['--img-dir', config['img_dir']])\n",
    "    cmd.extend(['--lr', str(config['lr'])])\n",
    "    cmd.extend(['--epochs', str(config['epochs'])])\n",
    "    cmd.extend(['--batch-size', str(config['batch_size'])])\n",
    "    cmd.extend(['--num-classes', str(config['num_classes'])])\n",
    "    cmd.extend(['--early-stopping', str(config['early_stopping'])])\n",
    "    cmd.extend(['--dropout', str(config['dropout'])])\n",
    "    cmd.extend(['--max-per-class', str(config['max_per_class'])])\n",
    "    cmd.extend(['--min-per-class', str(config['min_per_class'])])\n",
    "    \n",
    "    # Optional flags\n",
    "    if not config['freeze_layers']:\n",
    "        cmd.append('--no-freeze')\n",
    "    if config['dry_run']:\n",
    "        cmd.append('--dry-run')\n",
    "    \n",
    "    return cmd\n",
    "\n",
    "# Build the command\n",
    "command_args = build_command(config)\n",
    "\n",
    "print(\"üîß Fine-tuning Configuration:\")\n",
    "print(\"=\" * 40)\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"\\nüìù Generated Command:\")\n",
    "print(f\"  {' '.join(command_args)}\")\n",
    "\n",
    "log_message(f\"Configuration: {json.dumps(config, indent=2)}\")\n",
    "log_message(f\"Command: {' '.join(command_args)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0d2f9c",
   "metadata": {},
   "source": [
    "## 5. Execute Fine-tuning Command\n",
    "\n",
    "Run the finetune_coffeeCNN.py script using subprocess with parameter passing and real-time output streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76151951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the fine-tuning command\n",
    "print(\"üöÄ Starting Coffee CNN Fine-tuning...\")\n",
    "print(\"=\" * 50)\n",
    "print(\"üìù Real-time output will be shown below and logged to finetune_log.txt\")\n",
    "print(\"‚è±Ô∏è This process may take several minutes to complete...\")\n",
    "print()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Execute the command with real-time output\n",
    "return_code, stdout, stderr = execute_finetune_command(command_args, real_time_output=True)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Log execution summary\n",
    "summary = f\"\"\"\n",
    "{'='*50}\n",
    "EXECUTION SUMMARY\n",
    "{'='*50}\n",
    "Return Code: {return_code}\n",
    "Execution Time: {execution_time:.2f} seconds ({execution_time/60:.2f} minutes)\n",
    "Status: {'SUCCESS' if return_code == 0 else 'FAILED'}\n",
    "Output Model: {config['output']}\n",
    "Log File: {LOG_FILE}\n",
    "{'='*50}\n",
    "\"\"\"\n",
    "\n",
    "log_message(summary)\n",
    "print(summary)\n",
    "\n",
    "if return_code != 0:\n",
    "    print(\"‚ùå Fine-tuning failed! Check the log file for details.\")\n",
    "    if stderr:\n",
    "        print(f\"Error: {stderr}\")\n",
    "else:\n",
    "    print(\"‚úÖ Fine-tuning completed successfully!\")\n",
    "    print(f\"üíæ Model saved as: {config['output']}\")\n",
    "    print(f\"üìà History saved as: {config['output'].replace('.pth', '_history.json')}\")\n",
    "    print(f\"üìã Full log saved in: {LOG_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69127029",
   "metadata": {},
   "source": [
    "## 6. Monitor Training Progress\n",
    "\n",
    "Implement real-time monitoring of the training process by reading and displaying log file contents during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258dc033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor training progress by examining the log file\n",
    "def monitor_training_progress():\n",
    "    \"\"\"Monitor and display training progress from the log file.\"\"\"\n",
    "    print(\"üìä Training Progress Monitor\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Read the full log file\n",
    "    try:\n",
    "        with open(LOG_FILE, 'r', encoding='utf-8') as f:\n",
    "            log_content = f.read()\n",
    "        \n",
    "        # Extract key information\n",
    "        lines = log_content.split('\\n')\n",
    "        \n",
    "        # Find training epochs\n",
    "        epoch_lines = [line for line in lines if 'Epoch ' in line and '/' in line]\n",
    "        \n",
    "        if epoch_lines:\n",
    "            print(\"üîÑ Training Epochs Found:\")\n",
    "            for epoch_line in epoch_lines[-5:]:  # Show last 5 epochs\n",
    "                # Extract just the relevant part\n",
    "                if '] ' in epoch_line:\n",
    "                    content = epoch_line.split('] ', 1)[1]\n",
    "                    print(f\"  {content}\")\n",
    "        \n",
    "        # Find accuracy/loss information\n",
    "        acc_lines = [line for line in lines if ('Train Acc:' in line or 'Val Acc:' in line)]\n",
    "        if acc_lines:\n",
    "            print(\"\\nüìà Latest Training Metrics:\")\n",
    "            for acc_line in acc_lines[-4:]:  # Show last 4 accuracy lines\n",
    "                if '] ' in acc_line:\n",
    "                    content = acc_line.split('] ', 1)[1]\n",
    "                    print(f\"  {content}\")\n",
    "        \n",
    "        # Find best model saves\n",
    "        save_lines = [line for line in lines if 'Saved new best model' in line]\n",
    "        if save_lines:\n",
    "            print(f\"\\nüíæ Best Model Updates: {len(save_lines)} saves\")\n",
    "            if save_lines:\n",
    "                latest_save = save_lines[-1]\n",
    "                if '] ' in latest_save:\n",
    "                    content = latest_save.split('] ', 1)[1]\n",
    "                    print(f\"  Latest: {content}\")\n",
    "        \n",
    "        # Check for early stopping\n",
    "        early_stop_lines = [line for line in lines if 'Early stopping triggered' in line]\n",
    "        if early_stop_lines:\n",
    "            print(f\"\\nüõë Early Stopping: {early_stop_lines[-1].split('] ', 1)[1]}\")\n",
    "        \n",
    "        # Check for completion\n",
    "        completion_lines = [line for line in lines if 'Fine-tuning complete' in line]\n",
    "        if completion_lines:\n",
    "            print(f\"\\nüéâ Training Status: Complete\")\n",
    "        \n",
    "        # Show final validation accuracy\n",
    "        final_acc_lines = [line for line in lines if 'Best validation accuracy:' in line]\n",
    "        if final_acc_lines:\n",
    "            final_acc = final_acc_lines[-1]\n",
    "            if '] ' in final_acc:\n",
    "                content = final_acc.split('] ', 1)[1]\n",
    "                print(f\"üìä {content}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Log file not found. Run the training first.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading log: {e}\")\n",
    "\n",
    "# Monitor the current training progress\n",
    "monitor_training_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c4962",
   "metadata": {},
   "source": [
    "## 7. Parse and Display Results\n",
    "\n",
    "Parse the final results from the log file and display training statistics, best validation accuracy, and saved model information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae535e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_final_results():\n",
    "    \"\"\"Parse and display comprehensive results from the training session.\"\"\"\n",
    "    print(\"üìä Final Results Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Check if history file was created\n",
    "        history_file = config['output'].replace('.pth', '_history.json')\n",
    "        \n",
    "        if os.path.exists(history_file):\n",
    "            print(f\"üìà Training History File: {history_file}\")\n",
    "            try:\n",
    "                with open(history_file, 'r') as f:\n",
    "                    history = json.load(f)\n",
    "                \n",
    "                print(\"\\nüéØ Training Summary:\")\n",
    "                training_history = history.get('training_history', {})\n",
    "                \n",
    "                if 'best_val_acc' in training_history:\n",
    "                    print(f\"  Best Validation Accuracy: {training_history['best_val_acc']:.2f}%\")\n",
    "                if 'best_epoch' in training_history:\n",
    "                    print(f\"  Best Epoch: {training_history['best_epoch'] + 1}\")\n",
    "                if 'total_epochs' in training_history:\n",
    "                    print(f\"  Total Epochs Trained: {training_history['total_epochs']}\")\n",
    "                \n",
    "                # Show final losses/accuracies\n",
    "                if 'train_losses' in training_history:\n",
    "                    final_loss = training_history['train_losses'][-1]\n",
    "                    print(f\"  Final Training Loss: {final_loss:.4f}\")\n",
    "                \n",
    "                if 'val_accuracies' in training_history:\n",
    "                    final_val_acc = training_history['val_accuracies'][-1]\n",
    "                    print(f\"  Final Validation Accuracy: {final_val_acc:.2f}%\")\n",
    "                \n",
    "                print(f\"\\nüìä Data Statistics:\")\n",
    "                data_stats = history.get('data_stats', {})\n",
    "                if data_stats:\n",
    "                    total_samples = sum(data_stats.values())\n",
    "                    print(f\"  Total Training Samples: {total_samples}\")\n",
    "                    print(f\"  Classes Used: {list(data_stats.keys())}\")\n",
    "                    print(f\"  Samples per Class: {data_stats}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Error reading history file: {e}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è History file not found: {history_file}\")\n",
    "        \n",
    "        # Check if model file was created\n",
    "        if os.path.exists(config['output']):\n",
    "            model_size = os.path.getsize(config['output']) / (1024 * 1024)  # MB\n",
    "            print(f\"\\nüíæ Model File: {config['output']}\")\n",
    "            print(f\"  Size: {model_size:.2f} MB\")\n",
    "            print(f\"  Created: {datetime.fromtimestamp(os.path.getctime(config['output']))}\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå Model file not found: {config['output']}\")\n",
    "        \n",
    "        # Show log file stats\n",
    "        if os.path.exists(LOG_FILE):\n",
    "            log_size = os.path.getsize(LOG_FILE) / 1024  # KB\n",
    "            print(f\"\\nüìã Log File: {LOG_FILE}\")\n",
    "            print(f\"  Size: {log_size:.2f} KB\")\n",
    "            \n",
    "            # Count important events in log\n",
    "            with open(LOG_FILE, 'r', encoding='utf-8') as f:\n",
    "                log_content = f.read()\n",
    "            \n",
    "            epoch_count = log_content.count('Epoch ')\n",
    "            save_count = log_content.count('Saved new best model')\n",
    "            error_count = log_content.count('‚ùå')\n",
    "            warning_count = log_content.count('‚ö†Ô∏è')\n",
    "            \n",
    "            print(f\"  Epochs Logged: {epoch_count}\")\n",
    "            print(f\"  Model Saves: {save_count}\")\n",
    "            if error_count > 0:\n",
    "                print(f\"  Errors: {error_count}\")\n",
    "            if warning_count > 0:\n",
    "                print(f\"  Warnings: {warning_count}\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Results analysis complete!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error parsing results: {e}\")\n",
    "\n",
    "def show_log_tail(lines=30):\n",
    "    \"\"\"Show the last N lines of the log file.\"\"\"\n",
    "    print(f\"\\nüìù Last {lines} lines of log file:\")\n",
    "    print(\"-\" * 60)\n",
    "    tail_content = read_log_tail(lines)\n",
    "    print(tail_content)\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Parse and display final results\n",
    "parse_final_results()\n",
    "\n",
    "# Show recent log entries\n",
    "show_log_tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01856a22",
   "metadata": {},
   "source": [
    "## Additional Utilities\n",
    "\n",
    "Helper functions for working with the fine-tuning process and log files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e8fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional utility functions\n",
    "\n",
    "def view_full_log():\n",
    "    \"\"\"Display the complete log file content.\"\"\"\n",
    "    try:\n",
    "        with open(LOG_FILE, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        print(\"üìã Complete Log File Content:\")\n",
    "        print(\"=\" * 80)\n",
    "        print(content)\n",
    "        print(\"=\" * 80)\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Log file not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading log file: {e}\")\n",
    "\n",
    "def run_dry_run():\n",
    "    \"\"\"Run the fine-tuning script in dry-run mode to check data.\"\"\"\n",
    "    print(\"üèÉ Running dry-run to check data availability...\")\n",
    "    \n",
    "    # Create dry-run config\n",
    "    dry_config = config.copy()\n",
    "    dry_config['dry_run'] = True\n",
    "    dry_config['output'] = 'dry_run_test.pth'  # Won't be created\n",
    "    \n",
    "    dry_command = build_command(dry_config)\n",
    "    \n",
    "    # Execute dry run\n",
    "    return_code, stdout, stderr = execute_finetune_command(dry_command, real_time_output=True)\n",
    "    \n",
    "    if return_code == 0:\n",
    "        print(\"‚úÖ Dry run completed successfully - data is ready for training!\")\n",
    "    else:\n",
    "        print(\"‚ùå Dry run failed - check data availability\")\n",
    "    \n",
    "    return return_code == 0\n",
    "\n",
    "def check_model_files():\n",
    "    \"\"\"Check what model files are available in the current directory.\"\"\"\n",
    "    print(\"üìÅ Available Model Files:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    model_files = []\n",
    "    for file in os.listdir('.'):\n",
    "        if file.endswith('.pth'):\n",
    "            size_mb = os.path.getsize(file) / (1024 * 1024)\n",
    "            mod_time = datetime.fromtimestamp(os.path.getmtime(file))\n",
    "            model_files.append((file, size_mb, mod_time))\n",
    "            print(f\"  {file}\")\n",
    "            print(f\"    Size: {size_mb:.2f} MB\")\n",
    "            print(f\"    Modified: {mod_time}\")\n",
    "            print()\n",
    "    \n",
    "    if not model_files:\n",
    "        print(\"  No .pth model files found in current directory\")\n",
    "    \n",
    "    return model_files\n",
    "\n",
    "def cleanup_logs():\n",
    "    \"\"\"Archive the current log file.\"\"\"\n",
    "    if os.path.exists(LOG_FILE):\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        archive_name = f\"finetune_log_{timestamp}.txt\"\n",
    "        os.rename(LOG_FILE, archive_name)\n",
    "        print(f\"üì¶ Log file archived as: {archive_name}\")\n",
    "        return archive_name\n",
    "    else:\n",
    "        print(\"‚ùå No log file to archive\")\n",
    "        return None\n",
    "\n",
    "print(\"üõ†Ô∏è Utility functions loaded:\")\n",
    "print(\"  - view_full_log(): Display complete log file\")\n",
    "print(\"  - run_dry_run(): Test data availability without training\")\n",
    "print(\"  - check_model_files(): List available model files\")\n",
    "print(\"  - cleanup_logs(): Archive current log file\")\n",
    "\n",
    "# Quick status check\n",
    "print(f\"\\nüìä Current Status:\")\n",
    "print(f\"  Log file exists: {os.path.exists(LOG_FILE)}\")\n",
    "print(f\"  Expected model: {config['output']}\")\n",
    "print(f\"  Model exists: {os.path.exists(config['output'])}\")\n",
    "print(f\"  Script path: {SCRIPT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
